<span class="chapter-banner">Chapter 12</span>
# Incident Response
![](soc.jpg)

**Objectives**
1. Understand the role and procedures of a security operations center (SOC).
2. Install and configure a security information and event manager (SIEM) to detect threats across an environment using Splunk.
3. Learn the major components and processes of an incident response plan.
4. Understand the role of Threat Hunting and how it identifies security incidents in a network.

Information and cyber security can be summarized as the preventing, detecting, and responding to vulnerabilities and threats.  With the exception of the last chapter, much of this textbook has focused on the vulnerability side of infosec, whereas vulnerabilities in their most general form provide the opportunity for threats to succeed.  This chapter will focus on how organizations prepare, identify and react to threats.  It is the second part of the detection and response section that expands on the previous Forensics and Malware Analysis chapter.  Readers will learn about the systems used to aggregate data and how threats are found within networks and systems.  We will also cover administrative efforts of organizations that plan for security incidents.
## Security Information and Event Manager (SIEM)
Most medium to large organizations will invest in a system that aggregates logs from systems in their network.  A **security information and event management (SIEM)** solution enable analysts to search and filter system logs to identify events that occurred.  For instance, Windows Desktop logs fed into a SIEM will include logon events where an analyst can quickly and remotely identify who attempted logons on that system.  Using these log events, the SIEM is also capable of using saved advanced queries that can be configured to notify analysts when a pattern of events is detected.  Expanding on the previous example, an alert can be established within the SIEM that notifies analysts when a device has 5 consecutive failed logon attempts within a 1-minute window.  Such an alert could signal a brute force attack against a device or user account.  As you might have gathered, SIEMs are powerful and complex systems that enrich security teams *threat monitoring* within an environment.  

>[!tip] Tip - Pronouncing SIEM
>Yet another acronym that has great debate surrounding its pronunciation.  Your author is in the camp of pronouncing it as "SIM", while many other professionals, especially outside the United States, pronounce it as "SEEM".  
### Security Operations Center (SOC)
While most organizations have a natural flow of activity centered around a workday, attacks happen at any time.  Some global organizations operated all day which puts added pressure on security teams to always be monitoring the network.  Regardless, attackers and threat actors may become active at any time and security professionals must always be on guard should security events or incidents occur.  Given this need for multiple shifts of security professionals, many medium sized organizations outsource the labor needed to manage a SIEM to companies called *managed security service providers (MSSP)*.  Companies centralize and streamline security monitoring while maintaining a talent pool of security professionals that cover all daily shifts.  With enough customers, MSSPs achieve an economy of scale medium-sized organizations can't acquire on their own.

The entity at an organization responsible for maintaining, managing, and monitoring the SIEM, regardless of using an MSSP or insourcing within the company, is referred to as the **security operations center (SOC)**.  The SOC can be a loosely organized group of 1 or more individuals, or as simple as an email distribution list, who use the SIEM for threat monitoring.  The SOC can also be a formal department with several teams that have multiple offices and share dashboards on projectors, as illustrated with this chapter's cover art (generated by DALLE).

>[!tip] Tip - Breaking into Cybersecurity
>SOCs are in constant need of new analysts as the work is laborious and many analysts quickly get promoted to other security roles.  Many individuals find SOC Analyst roles as a pathway into the cybersecurity field due to high market demand.  Usually, these jobs expect some IT experience, such as 1-2 years doing help desk or working as a junior systems administrator.

No matter how you go about it, a SOC is expensive to set up and maintain.  It requires procuring costly services from a third party or hiring specialized professionals.  Usually, one person is not enough because it is unfair, or in some jurisdictions illegal, to require someone to be available 24 hours a day and 7 days a week.  Aside from the monitoring and response efforts, SOC team members must stay abreast of new threats and techniques while integrating them into their procedures.  In addition, the area experiences a high personnel turnover rate because the work is stressful and unending.  Analysts are often rotated to other duties as they may experience *alert fatigue* which can lead to mistakes when handling security events.  One such mistake is a false negative error, or missing a true positive, that causes a threat to go unheeded.
### Setting Up a SIEM
The following diagram illustrates the general setup for a SIEM within an organization's network.  It includes device types that feed into a SIEM solution stack that a SOC uses.

![[../images/12/siem_arch.png|SIEM Architecture|600]]

The primary interface of a SIEM solution is a web application, sometimes called a console.  Users of the console, such as SOC team members, log into the application through their browsers.  Ideally, this SIEM web application is only available to the devices for users who have a need to access it, and not available on the public internet.  Access to the system requires an account with valid credentials, username and password.  Once logged in, the users can begin querying the logs and conducting investigations.

>[!info] Info - SIEM Users
>SIEMs are powerful tools that can assist more than security personnel.  There may be additional use cases for system administrators and even developers to use the SIEM to monitor and troubleshoot the health of systems and applications.

A SIEM's lifeblood is the data that is fed into it.  Without a constant live stream of log files from various systems, there wouldn't be much relevant data for SOC analysts to query.  Almost any log that follows a structured data pattern can be sent to the SIEM over the network.  Usually, administrators will want to feed as much as possible into the SIEM to have the most opportunity to identify malicious events.  This typically includes alerts from security systems such as *end point detection and response (EDR)*, antivirus, and IDS/IPS systems, as well as logs from servers, workstations, and network equipment like routers and firewalls.

Log data is sent to an *ingestor* in a *push*, where the node initiates the sending, or *pull* method, where the ingestor initiates the data transfer.  This collection of data should be over encrypted channels, like TLS, to ensure that the data is not manipulated in transit.  Log ingestion usually uses authentication in addition to encryption to ensure only authorized devices send data.  This exchange could use *agentless* approaches in which a service account accesses the respective endpoint over secure protocols like SSH.  A more robust and stable approach is to use an *agent*, which is a software application installed on the device that collects and sends data to the SIEM.  The ingestor validates the sender and the data being consumed before preparing, parsing, and storing it.  SIEM administrators must consider how frequently to send the data to the ingestor.  Too frequently, such as every second, may cause network congestion or overwhelm the ingestor's resources.  However, running ingestions too far apart, such as once a day, degrades the SOC's ability to identify and respond to threats quickly and could also reach limitations with the amount of data being transferred at once.

>[!tip] Tip - Separation of Concerns
>The SIEM ingestor, database, and web server can all be installed on the same server, but it is a best practice to separate each function onto its own server or cluster of servers.  This provides flexibility with maintenance, disaster recovery, and troubleshooting issues.

Data sent to the database is stored and used by the SIEM's web application.  Most solutions will align the timestamps of logs to coordinated universal time (UTC) and then present the relative time to a user's selected time zone preference within their account.  When a SIEM user queries data through the application, a call is made to the database that retrieves the queried information.  You can imagine that the database will be very busy writing new data in large quantities alongside handling user queries.  Most SIEM solutions will speed up the query process by creating *indexes* of the data at regular intervals, such as daily.  Another design decision must be made reagrding the *retention period* of how long to store the data.  Data retained for too long may be needlessly expensive to support the indexing and storage costs while providing little value as it becomes less likely to be searched the older it gets.  Most organizations tend to use the retention period of one year, but this period could be higher or lower depending on the organization's needs.  

>[!activity] Activity 12.1 - Splunk Setup
> Splunk is a very popular SIEM solution that has all the modern features needed for security teams to identify and track threats in an environment.  Splunk offers a free license that has a limit of 500 MB ingestion a day and also excludes features such as alerting, user management, and data forwarding.  In this activity, I will demonstrate the local installation and features of Splunk using the BOTSV3 testing dataset.
> 
> After starting the Ubuntu VM in Bridge Adapter network mode, I launch a browser and navigate to the Splunk Enterprise registration page https://www.splunk.com/en_us/download/splunk-enterprise.html.  The form on this page requires the use of a business email - I recommend university students use their `.edu` emails as these are typically accepted by Splunk.
> ![[../images/12/splunk_activity_register.png|Splunk Registration|600]]
> Upon logging in, I reach the download page where I select the Linux tab and download the `.deb` installer.  This immediately takes me to the EULA acceptance page that I agree to and submit to commence the download.
> ![[../images/12/splunk_activity_download.png|Splunk DEB Download|600]]
> With the download completed, I open a terminal, update my system, install the dependency `curl` using `apt`, then finally install the Splunk `.deb` file using `dpkg`.  The `.deb` file is a Debian repository file that contains instructions and files to install Splunk.
> ```bash
> sudo apt update -y
> sudo apt install curl -y
> sudo dpkg -i ~/Downloads/splunk*.deb
> ```
> ![[../images/12/splunk_activity_curl_install.png|Installing Curl on Ubuntu|600]]
> The installation takes a minute to complete as there are a lot of files to unpack!
> ![[../images/12/splunk_activity_splunk_install.png|Installing Splunk Using Dpkg|600]]
> Splunk can be started using the Splunk binary stored in the `/opt/splunk/bin/` directory once the installation is complete.  The initial start requires acceptance of the license agreement using the `spacebar` and the `y` keys.  Additionally, the CLI requires entering the username and password to create a new user for web console access.
> ```bash
> sudo /opt/splunk/bin/splunk start
> ```
> ![[../images/12/splunk_activity_start.png|Startng Splunk|500]]
> ![[../images/12/splunk_activity_config.png|Accepting License and Creating User|500]]
> The installation completes in a few seconds and then returns me to the command prompt with a message to access Splunk over http://154-ubuntu:8000, the name of my virtual machine.
> ![[../images/12/splunk_activity_install_complete.png|Splunk Installation Complete|500]]
> I then open the browser in my VM and navigate to http://154-ubuntu:8000, although I could also have used http://127.0.0.1:8000.  I'm presented with a login page where I enter my username and password I set during the installation of the software.
> ![[../images/12/splunk_activity_login.png|Local Splunk Instance Login Page|400]]
> Splunk isn't very useful without data, so the next step is to populate the system with various data sources.  An organization would configure systems with agents and connections to continuously feed data into Splunk.  Because this is just a demonstration, I will be using a prepared test data set published on Splunk's GitHub page.  I navigate to https://github.com/splunk/botsv3 and download the BOTSV3 Dataset which is a curated set of logs used in Splunk's Boss of the SOC capture the flag challenge.
> ![[../images/12/splunk_activity_bots_download.png|BOTSV3 Download Page|500]]
> After the download completes, which takes a few minutes, I move the `.tgz` file from the downloads folder into the `/opt/splunk/etc/apps/` directory.  Then I unzip the download using gunzip and unarchive the unzipped file using `tar`.
> ```bash
> sudo mv ~/Downloads/botsv3_data_set.tgz /opt/splunk/etc/apps/
> sudo gunzip /opt/splunk/etc/apps/botsv3_data_set.tgz
> sudo tar -xvf /opt/splunk/etc/apps/botsv3_data_set.tar -C /opt/splunk/etc/apps/
> ```
> ![[../images/12/splunk_activity_extract_bots.png|Extracting BOTSV3 Dataset Into Splunk|500]]
> A restart of Splunk is required for the dataset to be recognized in the console.
> ```bash
> sudo /opt/splunk/bin/splunk restart
> ```
> ![[../images/12/splunk_activity_restart.png|Restarting Splunk|500]]
> Once restarted, I navigate back to the app (http://154-ubuntu:8000), press the Apps dropdown on the top navigation bar and select "Search & Reporting".
> ![[../images/12/splunk_activity_search_view.png|Splunk Search View|350]]
> 
> Afterwards, I enter the query/SPL `index=botsv3` into the search bar and change the time scope to "All Time" since this dataset is on the older side.  Millions of events are eventually loaded after a few minutes!
> ![[../images/12/splunk_activity_init_search.png|Intial SPL Search Over All Time|600]]
### SIEM Duties and Roles
Setting up, maintaining, and using a SIEM creates a large amount of work that grows depending on an organization's size and complexity.  For larger teams or organizations, the SIEM responsibilities may be divided among different individuals or groups.  The following list of roles and responsibilities attempts to outline how some organizations might choose to divide the duties needed for the SIEM.  

- **System Administrator** - Install the servers and configure end points with the ingestor.
- **SOC Analyst** - Triage alerts and escalates when a threat is identified.
- **SIEM Engineer** - Develop rules, dashboards, and reports for SIEM Analysts and managers.
- **Incident Responder** - Perform containment, eradication, and recovery of security incidents.
- **Threat Hunter** - Proactively create investigation scenarios and reviews where a threat could exist.

Each of the roles listed above will use the SIEM to accomplish their respective duties.  Some organizations may have one person perform multiple roles, whereas other organizations might rotate individuals between roles to cross train and avoid alert fatigue described earlier in the chapter.
### Available SIEM Tools
Many vendors create and sell commercial grade SIEM solutions.  Depending on the vendor, they may offer cloud-based *software as a service (SaaS)* or an on-premises environment where the servers are hosted on the customer's servers.  These systems can be very expensive, from tens of thousands of dollars for medium sized organizations up to hundreds of thousands or millions of dollars for large organizations.  Some of the most popular SIEM providers include Splunk, Rapid7 InsightIDR, and Sumo Logic, although there are many others in this crowded space.  Most of the providers offer relatively the same features but with varying user experiences.  At the time of this writing, Splunk has more than half of the market share, making it one of the most attractive systems to learn on. [^1]

There are also open-source and free SIEM solutions available that require on premise installation.  The HELK stack (https://thehelk.com/intro.html) that cobbles together various opensource tools including Elasticsearch, Logstash, and Kibana is a popular solution driven by community developers.  Another more recent and cohesive opensource solution is Wazuh (https://wazuh.com/) which has all the features of a modern SIEM solution.  In addition, Wazuh is compatible with the opensource host-based intrusion detection system (HIDS) software OSSEC.
### Capabilities of a SIEM
Most SIEMs offer a range of capabilities that are fairly consistent regardless of the solution selected.  But you must ensure in advance that the solution has all the features you expect before purchasing it.  Common features include the ability to collect large amounts of data and query it efficiently.  Saving queries, which can then be used as the logic for alerts and notifications increases the benefits of a SIEM.  Ideally, these alerts can be marked with risk priority or severity ratings that will organize analyst workloads by focusing on the most important events first.  Many modern SIEM solutions offer some type of scripting and built-in or custom automations to respond to incidents called *security orchestration, automation, and response (SOAR)*.  Usually SOAR modules are written in Python, or some other scripting language, which performs some task.  For example, a user account compromise incident requires that the user's account be disabled and active sessions terminated - having a button next to the incident that performs these tasks on Active Directory can save crucial time.  

>[!activity] Activity 12.2 - Splunk Investigation
>Once a SIEM is up and running, with data being regularly imported, SOC analysts and incident responders use the tool to identify and investigate system breaches.  In the last activity, I demonstrated the installation and ingestion of the BOTSV3 data set.  In this activity, I will continue where I left off and illustrate a simple investigation and how to use SPL to query datasets. With all 2 million events matched in the botsv3 index, I scroll down to the Fields navigation on the left pane just below the timeline.  Splunk will index every record by field and summarize each field's count statistic while providing a quick link to filter just those events.  I select "host" which lists all the hosts on the network and chose the "matar" option to filter only the events related to this host.
> ![[../images/12/splunk_activity_host_field.png|Host Field Navigation|550]]
> Once selected, I observe that the search field has been updated with a new SPL `host=matar`.  SPL is updated using the GUI; however, a much richer experience is to write your own SPL to include operators and logic to filter and derive information from the available data.  I append `| stats count by source` to the SPL and hit enter.  This query pipes all filtered matar results to the SPL command stats where all sources are counted and displayed in the Statistics tab in the results section.
> ```SPL
> index=botsv3 host=matar | stats count by source
> ```
> ![[../images/12/splunk_activity_stats.png|Using Pipes and Commands in SPL|600]]
> This view helps me understand the types and volume of records related to the host.  Scrolling through the stats summaries, I find events for `stream:smtp`.  SMTP, a protocol used for email, can be interesting so I select the entry and press View events to update the SPL and show all SMTP events on the host.
> ![[../images/12/splunk_activity_smtp_filter.png|SMTP Search|300]]
> The events pane is populated with SMTP events for the matar host.  Looking at the first record, I observe an odd subject line of a sent email "Fw: All your datas belong to us".
> ![[../images/12/splunk_activity_email_1.png|Email Forward Discovery|500]]
> Perhaps this user of the matar host is a victim of ransomware and this is a ransom note being forwarded.  I am curious if any other emails have a similar subject line.  The act of finding data and searching elsewhere for similar artefacts is called *pivoting*.  While still using the botsv3 index, I query `subject:"All your datas*"`.  The star symbol is a wildcard, which means any other characters.  
> ![[../images/12/splunk_activity_subject_search.png|Subject Line Pivot Search|500]]
> Looks like there are two hits for this subject line with the second event being the original email with a src_ip address of 104.47.34.50 - perhaps this is the attacker's IP!
> ![[../images/12/splunk_activity_srcip.png|Attacker IP Address Identified|400]]

SIEMs usually have reporting and dashboard features powered by the query system.  A dashboard is useful to analysts and their management as it enables them to focus their attention on the types of risks that matter most.  Deriving reports from the SIEM is typically important to SOC managers to identify security and performance trends of the operation.  They can be used to justify the investment in the SIEM by clearly describing the number of malicious events detected, for example.

>[!activity] Activity 12.3 - Splunk Dashboards and Reports
>SIEM solutions, like Splunk, will offer its users the ability to pull out information from the ingested data sets into reports, widgets, and dashboards.  Within Splunk, these features are supported by the SPL where queries can be saved and used to build out visualizations and to deliver notifications and reports.  These features enable SOC analysts to monitor aggregated data at a higher level and then drill down into the data as needs arise.  In the last two activities, I demonstrated the setup and use of Splunk to conduct an investigation.  In this activity, I will show how to setup reports, widgets, and dashboards within Splunk using the same BOTSV3 data set as the previous two activities.
>
>Suppose I had an interest in tracking the most frequent IP addresses found within the data sets imported into Splunk.  I could build an SPL that uses the stats command to summarize basic volume information for each host.  The host data can be sorted by descending order and display the top 10 results.  The following SPL accomplishes this desire, which pulls the top 10 hosts by volume.
>```SPL
>index=botsv3 | stats count as cnt by host | sort cnt desc | head 10
>```
>![[../images/12/splunk_activity_top10.png|Top 10 Hosts SPL|650]]
>I won't want to retype this SPL each time I need the data.  Fortunately, Splunk has a Save feature available above the SPL field bar.  Another feature is the ability to turn a query result into a report also using the Save feature.  Pressing the Save As dropdown reveals the Report option, which I select and Title the report "Top 10 Hosts" with the Time Range Picker set to Yes before hitting Save.
>![[../images/12/splunk_activity_report.png|Creating a Report From SPL|450]]
>After hitting Save, I am presented with an option to View the report.  Pressing View opens the report page with my SPL data.  Anytime I want to get the latest top 10 hosts, I only have to open up this report using the Reports link in the top header.  Premium editions of Splunk can also email reports on a schedule, which will be outside the scope of this activity.
>![[../images/12/splunk_activity_report_view.png|Viewing Splunk Report|600]]
>It is fairly common to create and deliver reports to stakeholders using Splunk.  Another common feature is the use of visualization gadgets and dashboards.  From a SOC analyst's point of view, having a quick reference to identify a security problem in the network promptly is highly desirable.  I can craft an SPL that will identify failed login attempts on Windows systems that could be an indicator of a brute force attack.  Windows event 4625 is the standard event for failed logins which will be a key source of data for my query.
>```SPL
>index=botsv3 source=* EventCode=4625 | stats count as cnt
>```
>![[../images/12/splunk_activity_failed_login.png|Failed Login SPL|350]]
>The SPL yields a count of 5 failed logins presented in the Statistics tab.  The result of a query can be used in a visualization that can display the data in a more meaningful way.  For example, I can create a visualization that will help gauge if the value is low, normal, or concerning.  Clicking the Visualization tab, I select the radial gauge type.
>![[../images/12/splunk_activity_visualization.png|Visualization Radial Gauge Selection|300]]
>With the radial gauge selected, I can format it to distinguish low, moderate, and concerning levels of failed logins.  I choose the Format tab, Color Ranges from the left menu, and then the Manual subtab to enter ranges zero to five as green, five to ten as yellow, and ten to twenty as red.
>![[../images/12/splunk_activity_radial_settings.png|Radial Setting Configuration|400]]
>This gauge would look great in a dashboard that can quickly reference the security standing of logins on the network.  A dashboard is meant to be regularly monitored and could even be used as a constant display in an office like a SOC for everyone to quickly view.  I choose the Save As dropdown and select New Dashboard.
>![[../images/12/splunk_activity_dashboard_create.png|Saving Gauge Into New Dashboard|500]]
>Pressing New Dashboard creates a popup window to configure the new dashboard's initial settings.  I enter "Monitoring" for the Dashboard Title and choose "Classic Dashboard" before pressing Save to Dashboard and then View Dashboard.
>![[../images/12/splunk_activity_config_dash.png|Initial Dashboard Settings|300]]
>The initial dashboard display is off to a great start, but it needs more context using the title and sub headers.  I press the Edit button in the upper right corner and name the section "Brute Force" and the widget "Failed Windows Logons", then hit Save.  The final dashboard looks much clearer!
>![[../images/12/splunk_activity_final_dash.png|Final Dashboard|550]]
>I can add new visualizations, sections and change the format of the dashboard to meet my security monitoring needs.  Using the Dashboards tab in the top menu will let me navigate back to any of my dashboards at will.
## Threat Hunting
So far, we have explored how a SOC analyst would use a SIEM to alert and investigate potential security incidents based off feeds of system events.  The SOC analyst reacts to detections by responding to alerts in an effort to ensure the security of networks and systems.  However, another approach to security, while leveraging the power of the SIEM, is **threat hunting** that proactively searches for potential cyber threats.  The role of a threat hunter, who typically works in the SOC and uses the SIEM, can be a dedicated individual, team, or a shared role.  Many SOCs rotate personnel between roles to keep team members engaged and challenged.
### Process of Hunting
Threat hunting starts with an idea or hypothesis with the assumption that a threat actor has conducted some malicious activity that has yet to be discovered in the network.  This ideation phase includes studying how that attack would transpire, which technologies and protocols it would use, and considers the indicators of compromise (IoC) and artifacts associated with the attack.  Armed with the anticipated attacker behavior and targets, the threat hunter will next analyze systems searching for evidence of the threat.  Hopefully this results in nothing being identified, not due to a lack of quality, but due to the fact that there was no security breach!  In the final phase of threat hunting, a collection of IoCs and artifacts could be fed back into the SIEM in the form of SPLs, alerts, dashboards, and reports, where prudent.  The threat hunter will typically prepare a project report that describes their efforts starting from the idea, research and results of the investigation.  Of course, should the threat hunter detect a threat, they would immediately escalate to the SOC's incident responders.
### Hunt Methodologies
The real art of a threat hunt centers around the initial idea phase.  Threat hunters must identify a plausible threat scenario on which to base their investigations.  These ideas can be driven by a few categories of research as follows:

1. **Hypothesis Driven** - Anticipated new threat behaviors including tools, techniques, and procedures
2. **Known IoC/IoAs** - Indicators collected from existing threat behaviors and *threat intelligence* resources
3. **Advanced Analytics** - Use of big data and statistical measurements to identify anomalous activity

Realistically, any reasonable idea could be worth exploring.  Sometimes a threat hunt can center around an organization's specific activity.  For instance, an organization can plan for a sensitive data migration between vendors.  Under this circumstance, a threat hunter can design an investigation with the data transfer context in mind.  Other common threat hunting scenarios will focus on common, popular, or well publicized attacks centered around a powerful exploit.  A great resource for such attacks is maintained by the Cybersecurity & Infrastructure Security Agency (CISA) in their Known Exploited Vulnerabilities Catalog (https://www.cisa.gov/known-exploited-vulnerabilities-catalog).

### Threat Intelligence
Many vendors offer **threat intelligence** services that attempt to build profiles of threat actors including their tools, techniques, and procedures.  This information is highly valuable to incident responders during attribution efforts which attempts to determine who compromised them.  But threat intelligence can also be a valuable resource to threat hunters during the idea and analysis phases of their investigations.  

> [!activity] Activity 12.4 - Threat Intelligence Using MITRE ATT&CK Framework
>  Perhaps the greatest resource to threat hunters developing scenarios using the known IoCs method is MITRE's ATT&CK framework (https://attack.mitre.org/).  We've covered this resource in earlier chapters which emphasized the categorization of attack tools, techniques, and procedures (TTP).
>  ![[../images/12/mitre_attack.png|MITRE ATT&CK Framework Website|600]]
>  MITRE's database includes dozens of threat actor groups on the https://attack.mitre.org/groups/  page.  Many of these groups are referred to by different names depending on the organizations that track them.  Navigating to the group page, I find an interesting North Korean state sponsored group, Lazarus.
>  ![[../images/12/threat_activity_groups.png|Lazarus Group Summary on MITRE ATT&CK|600]]
>  Selecting the group's link reveals much more information on the threat, including the campaigns that have been attributed to them.  In this campaign, a list of techniques is provided that include further details on how to detect them within a network.  Aggregating several of these techniques could build a case worthy of a threat hunt!
>  ![[../images/12/threat_activity_campaign.png|Operation Dream Job Lazarus Campaign Techniques|600]]
>  The many-to-many nature of the ATT&CK framework affords us the ability to start developing threat hunts based on specific techniques.  Navigating to https://attack.mitre.org/techniques/enterprise/  reveals hundreds of available techniques associated with threat actors.
>  ![[../images/12/threat_activity_techniques.png|Threat Actor Techniques|600]]
>  Technique "Bypass User Account Control" T1548 catches my eye.  I follow the technique link (https://attack.mitre.org/techniques/T1548/002/) and scroll down to the Detection section of the technique, which shows several methods to detect malicious behavior.  
>  ![[../images/12/threat_activity_detection.png|T1548 Detection Methods|600]]
>  With this information, I can begin building a threat hunt and search criteria within the SIEM to detect malicious behavior.  
## Incident Response
The detection of a breach in security should cause an immediate reaction to remediate the threat and recover systems known as **incident response**.  The *incident responder* is another security professional role held by an individual who could be associated with the SOC team.  However, for smaller organizations, this role may not be held by someone in the organization and instead rely on a third party to perform incident response services.  This is usually a good idea as most organizations do not have frequent incidents that would warrant having a full-time incident responder available.  Similarly, as SOC analysts and threat hunters use the SIEM to detect security breaches, the incident responder uses the system to perform their investigations.  They use the data within the SIEM to forensically identify where the initial breach occurred, the activity performed by the threat actor, and all the systems affected by the incident.

Incident response by its nature is alerted to incidents from the efforts of other roles.  Usually, the SOC or threat hunting teams will validate a security incident and escalate the issue to an *incident response team (IRT)*.  While the graphic below demonstrates a delineation between the roles of the SOC, threat hunters, and incident responders, the reality of who is responsible for the duties of these roles will vary, depending on the organization.

![[../images/12/irt_escalate.png|Escalation Paths to Incident Response|500]]

As described earlier in this chapter, the SIEM will be programmed to raise alerts to SOC analysts, who triage and validate security concerns, while threat hunters conduct proactive investigations based on threat intelligence.  In both efforts, any verified breach of security would be escalated to incident responders.

>[!activity] Activity 12.5 - Security Incident
>Take a moment and consider how you would answer the following:
>1. Define a security incident vs a security event?
>2. Describe 3 examples of security incidents and security events.

While it may be tempting to use the terms security *incident* and security *event* interchangeably, they are distinct from each other.  A **security event** is an occurrence of an activity that is of interest to the safety of a system.  These are often found as items within system logs and pertain to a feature of the system, such as network request block or a user authorization.  One or more security events could indicate a **security incident** where a control to protect the safety of data or a system is bypassed exposing the system or its data to unauthorized parties. 
### Phases of Incident Response
The lifecycle of incident response efforts has two circular flows that progress the states between phases.  Not all organizations formally approach incident response this way; however, mature organizations put a lot of resources into being ready should a security incident occur.  Having a well-defined lifecycle reduces the impact and duration of security incidents that contribute to an organization's financial standing.

A long cyclical arch between *preparation* and *post-incident recovery* phases strengthens an organization's incident response posture.  Such a preparation reinforces the cyclical relationship between *detection and analysis* and the *containment and eradication* phases.  These phases require an iterative approach to ensure the complete mitigation of an existing threat.  Upon completion of this circular flow, the incident response effort moves to the *post-incident recovery* phase.

![[../images/12/incident_phases.png|The Phases of Incident Response|600]]

Each phase in the lifecycle contains many processes and requires the coordination of several parties in an organization.  It can be very chaotic for an organization during an active security incident as stress levels will be high and information will be unavailable to make informed decisions.  The **preparation** phase, which is continuous, includes many activities that are conducted prior to an incident that will attempt to position the organization to handle the incident.  The more effort that is spent in this phase, the more ready an organization will be when responding to an incident.  During this phase, an *incident response plan* is developed which defines or classifies security incidents, describes roles and responsibilities, as well as communication plans.  It is important that a communication strategy on the handling of security incidents be agreed upon during the preparation phase so that members of the organization know who they can turn to for incident status updates.  Other ideas developed during the preparation phase include how incidents will be tracked, as well as the types of reports needed to communicate information about the incident.  This phase will also designate who the members of the IRT are, as well as their responsibilities.  It is beneficial for the organization to train and test their incident capabilities and then feed lessons learned back into the incident response plan. 

Another aspect of the preparation phase is the development of *playbooks* that incident responders and SOC analysts can use, should an incident occur.  These playbooks are developed, usually as the result of training exercises that highlight gaps in the program, as both procedures for personnel to follow as well as system automations to expedite tasks.  It is often found that bottlenecks occur during incidents when key personnel, such as a system administrator, can't be located and are desperately needed to perform some action.  For example, a playbook might consist of a procedure that identifies how a brute force attack against a Windows Active Directory user account is detected and responded to which instructs a SOC analyst to disable that user's account.  That account can be disabled using an automation script that is embedded in the SIEM/SOAR platform by a press of a button, eliminating the need to find the system administrator.

Earlier in this chapter, the development of the SIEM and its detections were introduced in which I demonstrated how brute force attempts could be identified using the Windows Event 4625 (failed logon attempt) and Splunk's visualizations.  This type of information is critical during the **detection and analysis** phase of the incident response lifecycle.  Here, SOC analysts and threat hunters will discover breaches of security from multiple attack vectors, indicators of compromise, and other sources.  Sometimes alerts originate from users in the organization, a third party like a regulator, customers, or security researchers.  Some sources and detections are more reliable, providing stronger indications that security has been breached by a threat and should therefore be given higher priority when evaluating.

>[!activity] Activity 12.6 - Splunk Enterprise Security
>In a previous activity within this chapter, I demonstrated establishing a detection manually centered on a brute force attack on Windows.  We also explored the hundreds of tools, techniques, and procedures (TTPs) outlined within MITRE ATT&CK framework and found even more resources from which to build detections.  Manually creating SPLs, alerts, and dashboards to monitor all these threats would require a lot of resources that every organization caring for security would have to repeat the same level of effort, which is entirely inefficient.  Therefore, Splunk has developed configured solutions that kickstart an organization's detections with prewritten SPLs, alerts, and dashboards based on the most common threats called Splunk Enterprise Security.
>
>Enterprise Security offered by Splunk is a premium solution designed for defense, prevention, and breach response.  Splunk users can install a trial version of the plugin package to experiment with before buying.  More information about the product can be found at https://www.splunk.com/en_us/products/enterprise-security.html.
>![[../images/12/enterprise_activity_homepage.png|Splunk Enterprise Security Homepage|600]]
>Because Splunk is the most widely adopted SIEM, and Enterprise Security is a very popular plugin to quickly enable organizations to get threat detection up and running, readers are strongly encouraged to take advantage of Splunk's free course "Introduction to Enterprise Security" (https://www.splunk.com/en_us/training/course-catalog.html?filters=filterGroup1FreeCourses&search=enterprise).
>![[../images/12/enterprise_activity_course.png|Splunk Course Catalog|600]]
>Registration to the course is free and walks the learner through the use case, workflow, and interface of the tool.  The content is delivered in video format and concludes with an 11-question multiple choice quiz that can be taken unlimited times but requires a 75% to pass.  Upon passing, you are awarded a certificate of completion that would look great on a resume!
>

The detection and analysis phase usually results in an escalation to respond.  The **containment and eradication** phase picks up this escalation and includes activities to stop the incident from getting worse.  This is when most incident responders will first hear of a given incident.  The scope of the incident will inform the level of containment that is needed.  For instance, a business email compromise of one user has a smaller scope than a company's primary database being leaked on the darknet.  Containing a threat can be challenging as many incidents are dynamic and complex.  Some strategies include the resetting of accounts, implementation of anti-malware solutions, and segregating of networks.  During the containment phase, evidence gathering efforts are conducted to preserve information surrounding the incident.  

Incident responders must "think like the attacker" to understand their motives and methods which will assist them to remove the threat.  They will consider the phases of the attack cycle, like the Cyber Kill Chain introduced in the Information Security chapter of this textbook.  Great responders have a strong knowledge of the attack phases also covered in previous chapters, such as reconnaissance, information gathering, exploitation, and post exploitation, with a strong emphasis on post exploitation.  The incident responder may include, or involve, malware analysis techniques to fully understand the scope of the incident.  They will also correlate events within the SIEM and *pivot* to analyze other infections within the network.  Once confident that an incident is contained, the responders will move to eradicate the threat.

Eradication efforts include remediating the initial access vector and removing any persistence techniques deployed by the attacker.  It can be very challenging to identify each of these entry points which is why the containment and eradication phase must feed back into the detection and analysis phase to ensure that a threat is removed and not able to re-enter the network.  Eventually, all the evidence of the incident, the extent of the damage caused, the removal of the threat and the remediation of access is complete, the incident transitions into the **post incident** phase of the lifecycle.

Once the organization is confident in the eradication of the threat, they must recover from the incident.  Some techniques used include restoring systems from backups and reintroducing users and customers back on to the organization's systems.  The post-incident phase will include a *root cause analysis (RCA)* and lessons learned that will feed back into the organization's incident preparation program to better prevent and respond to future incidents.  Usually, an *incident report* is developed that details everything about the incident, including how it started and how it was recovered.  This information is also useful to customers, investors, regulators, and internal key stakeholders who often have a vested interest in the organization's security of data and systems.
### The Incident Response Plan
Organizations memorialize their program for preparing and handling security incidents within a formal document called an **incident response plan**.  This document is usually comprised of a requirements section that outlines each system important to the organization.  Each system may be required to have a system level plan that includes the names and contact information of administrators, diagrams and locations of the systems, and procedures for collecting logs, administering access, and handling general incidents.  

The plan document must describe the types of security risks that would invoke the use of the plan while describing the recommendations that outline the phases of the incident response lifecycle.  This document defines what an incident is and suggests communication and escalation strategies, usually as a *call tree* or a hierarchical responsibility matrix, that specifies who is responsible for informing others in the organization.  Risk severities alongside the timeliness of expected outcomes could be included in the plan as a way to express how quickly responses should be prioritized.

>[!tip] Tip - Incident Response Planning Guideline
>University of California Berkeley's Information Security Office has a wonderful Incident Response Planning Guideline (https://security.berkeley.edu/incident-response-planning-guideline) that prescribes requirements for all systems administrators to adhere to in support of incident response.

Most security departments are responsible for the development and maintenance of the incident response plan.  It is common for regulators and customers to express an interest or requirement that a plan be in place before they are willing to engage in business.  The plan is a central document that is usually reviewed during information security audits, such as the SOC2 or ISO 27001/2.

### Cyber Liability Insurance
A misconception with cyber liability insurance is that its purpose is to make an organization whole after an expensive security incident.  While that is partially true, cyber liability insurers are often more of a partner that extends response capabilities.  Many small and medium-sized organizations do not maintain in-house expertise to conduct forensic investigations or to handle the legal ramifications from regulators and customers.  Yet at the same time, it would be expensive for an organization to establish relationships and retainers with incident response service providers.

>[!warning] Warning - Legal Reporting Requirements
>Almost every jurisdiction has different security incidents or data breach reporting requirements.  Some are as soon as 48 hours, whereas others may be 60 days and are often bounded by conditions of volumes or types of data affected.  Such requirements are expected by states, governments, regulatory bodies, and even customers.  Most organizations' general counsel and legal teams do not have expertise with the legal requirements for security incident response.  It is therefore highly recommended to retain legal counsel that has expertise with incident response prior to having an incident to avoid violations of law.

This is where the value of a cyber liability insurer comes into play as they maintain a list of pre-approved and vetted vendors that have expertise with incident response ranging from legal, technical, and communication services.  These vendors can be invoked quickly through the insurance claims process that typically has a 24-hour hotline and response time to assist organizations during security incidents.  Perhaps the most important line within an organization's Incident Response Plan might be to reach out to the cyber liability insurer if an incident occurs.
## Exercises

>[!exercise] Exercise 12.1 - SIEM Setup
>In this task, you will install Splunk on your Ubuntu VM, import event data, and build queries, reports, and dashboards to analyze events.
>#### Step 1 - Install Splunk Enterprise
>Using your Ubuntu VM in Bridge Adapter network mode, launch a browser and navigate to [https://www.splunk.com/en_us/download/splunk-enterprise.html](https://www.splunk.com/en_us/download/splunk-enterprise.html) and fill out the Create Account form with your (.edu) email address.
>
>Upon login, you should reach the download page [https://www.splunk.com/en_us/download/splunk-enterprise.html?locale=en_us](https://www.splunk.com/en_us/download/splunk-enterprise.html?locale=en_us) .  Select Linux and download the ".deb" installer.
>
>Launch a terminal and install curl and the DEB file to install Splunk Enterprise.
>```bash
>sudo apt update -y 
>sudo apt install curl -y 
>sudo dpkg -i ~/Downloads/splunk*.deb 
>```
>#### Step 2 - Setup Splunk
>Start Splunk within your launched Ubuntu VM terminal.  When launching for the first time, you will be presented with the license agreement.  Use the "spacebar" and "y" keys to accept the terms.  Follow the CLI questions to select a username and password.
>```bash
>sudo /opt/splunk/bin/splunk start 
>```
>Once the setup is complete and Splunk is running, launch a web browser within your Ubuntu VM and navigate to [http://ubuntu:8000](http://ubuntu:8000/) or http://127.0.0.1:8000 where you'll be presented with your stand-alone instance of Splunk Enterprise.
>
>Login with the credentials you used during the setup.
>#### Step 3 - Load Data
>From within your Ubuntu VM, launch a browser and navigate to [https://github.com/splunk/botsv3](https://github.com/splunk/botsv3) and download the "BOTS V3 Dataset".  It is about 320 MBs, which may take 10 minutes or more to download.  This dataset is a curated set of logs used in Splunk's Boss of the SOC CTF challenge.
>
>Move the downloaded botsv3 data set to "/opt/splunk/etc/apps/" and unzip the contents using gunzip and tar.
>```bash
>sudo mv ~/Downloads/botsv3_data_set.tgz /opt/splunk/etc/apps/ 
>sudo gunzip /opt/splunk/etc/apps/botsv3_data_set.tgz
>sudo tar -xvf /opt/splunk/etc/apps/botsv3_data_set.tar -C /opt/splunk/etc/apps/ 
>```
>Restart Splunk for the upload botsv3 data set/index to become available.
>```bash
>sudo /opt/splunk/bin/splunk restart 
>```
>Once restarted, navigate to your Splunk instance, and select Apps and then "Search & Reporting".
>
>Change the time scope to "All time" and search the term `index=botsv3` to discover all available records.  Wait a few minutes and observe that millions of events loaded.
>```SPL
>index=botsv3
>```
>#### Step 4 - SPL/Query
>With all 2 million events matched in the botsv3 index, scroll down to the Fields navigation on the left pane just below the timeline.  Select "host" and choose the "matar" host.
>
>Once selected, observe that the search bar now includes `host=matar` in the query.  Append `| stats count by source` to the query and hit enter.  This query pipes all filtered matar results to the SPL command stats where all sources are counted and displayed in the Statistics tab in the results section.
>```SPL
>index=botsv3 host=matar | stats count by source 
>```
>Scroll to the bottom of the Statistics page and select the "stream:smtp" and "View Events". 
>
>Review the first result in the Events pane.  The first event should be an Outlook email from Grace Hoppy with the subject "Fw: All your datas belong to us".
>
>While still using the botsv3 index, query `subject:"All your datas*"` and observe that there are 2 hits.  The wildcard * in SPL is a placeholder for any number of characters.  Observe that the second event is the original email and has a src_ip address of 104.47.34.50.
>```SPL
>index=botsv3 subject:"All your datas*"
>```
>#### Step 5 - Reports
>The following query gathers the top 10 source IP addresses with `count: index=botsv3 | stats count as cnt by host | sort cnt desc | head 10`.  Once the SPL is complete, press the Save As dropdown in the top right corner and select Report.
>```SPL
>index=botsv3 | stats count as cnt by host | sort cnt desc | head 10
>```
>Title the report "Top 10 Hosts", Time Range Picker as Yes, and hit Save.
>
>Once the report is created, press the View button.
>
>Review the report and observe that it can be refreshed and exported at any time for reference.
>#### Step 6 - Visualizations and Dashboards
>In this step you will develop a radial gauge visualization to enhance our dashboard. Create a new query that counts the number of failed Windows logons that could indicate a bruteforce attack.
>```SPL
>index=botsv3 source=* EventCode=4625| stats count as cnt 
>```
>Once the query is entered, select the Visualization subtab and choose the radial gauge type.
>
>With the Radial gauge selected, choose Format, Color Ranges, and change the green range to 0-5, yellow range to 6-10, and red range to 11-20. These thresholds would typically be based off normal or expected behavior over time.
>
>Now that the gauge is configured with our thresholds, select the Save As and New Dashboard.
>
>Enter the Dashboard Title as "Monitoring", select "Classic Dashboards" and press Save to Dashboard.
>
>Select the View Dashboard button and observe that our Monitoring Dashboard has the radial gauge, but it excludes a title and/or context. Press the Edit button in the upper right corner and name the section "Brute Force", and name the widget "Failed Windows Logons", then hit Save.
>#### Step 7 - Challenge
>Find at least one other event worth monitoring from a security context. It doesn't have to be a Windows Event, but you can use [https://www.xplg.com/windows-server-security-events-list/](https://www.xplg.com/windows-server-security-events-list/) for inspiration. Create a query and a Visualization (your choice on type). Configure the visualization and add it to the Monitoring Dashboard with an appropriate title. 
>
>In a short paragraph, describe why you selected the query/visualization to monitor, its relevance to security, and how to interpret the information it presents.

>[!exercise] Exercise 12.2 - Splunk Enterprise Security
>In this task, you will register and complete Splunk's free eLearning course "Introduction to Enterprise Security". Splunk is one of the most popular SIEM tools in the industry. Evidencing your completion of the course is a great resume builder while expanding your knowledge in security.
>#### Step 1 - Register For Course
>Navigate to [https://www.splunk.com/en_us/training/course-catalog.html?filters=filterGroup1FreeCourses](https://www.splunk.com/en_us/training/course-catalog.html?filters=filterGroup1FreeCourses) and find the "Introduction to Enterprise Security" course.
>
>Press the Register link and then press the ENROLL button.
>
>Log in to Splunk using your existing account (or create one).
>#### Step 2 - Watch the Assigned Videos
>Once you've enrolled in the eLearning course, you may start the Video coursework. Watch the videos and take notes! You can re-watch the videos at any time and as many times as you'd like.
>#### Step 3 - Take the Quiz
>Once you've studied the videos, you should be ready for the quiz.  There are 11 multiple choice questions that are untimed and can be retaken as many times as you need. You must achieve a score of 75% or greater to pass the course. 
>
>Congrats! Consider adding your completion of this course to your LinkedIn profile and/or your resume!

[^1]: Splunk - Market Share, Competitor Insights in Security Information And Event Management (SIEM); 6 Sense; April 7th, 2024; https://6sense.com/tech/security-information-and-event-management-siem/splunk-market-share